{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gluonnlp \n",
    "!pip install pandas \n",
    "!pip install tqdm\n",
    "!pip install mxnet\n",
    "!pip install sentencepiece==0.1.91\n",
    "!pip install transformers==4.8.2\n",
    "!pip install torch==1.8.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dill --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p Model/polarity_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jprcZhTyetFF"
   },
   "source": [
    "# 모듈 import 및 전역 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1662696688692,
     "user": {
      "displayName": "정용빈",
      "userId": "11947955993359770436"
     },
     "user_tz": -540
    },
    "id": "8LDwADWNMpsC"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import trange\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "PADDING_TOKEN = 1\n",
    "S_OPEN_TOKEN = 0\n",
    "S_CLOSE_TOKEN = 2\n",
    "\n",
    "do_eval=True\n",
    "\n",
    "polarity_classification_model_path = './Model/polarity_classification/'\n",
    "\n",
    "train_data_path = './data/asc/train_asc_9_1_emoji_not_removed_clova.jsonl'\n",
    "dev_data_path = './data/asc/dev_asc_9_1_emoji_not_removed_clova.jsonl'\n",
    "\n",
    "max_len = 256\n",
    "batch_size = 8\n",
    "base_model = \"kykim/electra-kor-base\"\n",
    "learning_rate = 3e-6\n",
    "eps = 1e-8\n",
    "num_train_epochs = 20\n",
    "classifier_hidden_size = 768\n",
    "classifier_dropout_prob = 0.1\n",
    "\n",
    "entity_property_pair = [\n",
    "    '제품 전체#일반', '제품 전체#가격', '제품 전체#디자인', '제품 전체#품질', '제품 전체#편의성', '제품 전체#인지도', '제품 전체#다양성',\n",
    "    '본품#일반', '본품#디자인', '본품#품질', '본품#편의성', '본품#다양성', '본품#가격', '본품#인지도',\n",
    "    '패키지/구성품#일반', '패키지/구성품#가격', '패키지/구성품#디자인', '패키지/구성품#품질', '패키지/구성품#편의성', '패키지/구성품#다양성',\n",
    "    '브랜드#일반', '브랜드#가격', '브랜드#디자인', '브랜드#품질', '브랜드#인지도',\n",
    "                    ]\n",
    "\n",
    "polarity_id_to_name = ['positive', 'negative', 'neutral']\n",
    "polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "special_tokens_dict = {\n",
    "    'additional_special_tokens': ['&name&', '&affiliation&', '&social-security-num&', '&tel-num&', '&card-num&', '&bank-account&', '&num&', '&online-account&']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGmH15hCeqhJ"
   },
   "source": [
    "json 및 jsonl 파일 read, write 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1662696697330,
     "user": {
      "displayName": "정용빈",
      "userId": "11947955993359770436"
     },
     "user_tz": -540
    },
    "id": "6vGeHU4yP2Sg",
    "outputId": "30df52ca-3173-4dfc-a56d-1325650f5c6d"
   },
   "outputs": [],
   "source": [
    "def jsonload(fname, encoding=\"utf-8\"):\n",
    "    with open(fname, encoding=encoding) as f:\n",
    "        j = json.load(f)\n",
    "\n",
    "    return j\n",
    "\n",
    "\n",
    "# json 개체를 파일이름으로 깔끔하게 저장\n",
    "def jsondump(j, fname):\n",
    "    with open(fname, \"w\", encoding=\"UTF8\") as f:\n",
    "        json.dump(j, f, ensure_ascii=False)\n",
    "\n",
    "# jsonl 파일 읽어서 list에 저장\n",
    "def jsonlload(fname, encoding=\"utf-8\"):\n",
    "    json_list = []\n",
    "    with open(fname, encoding=encoding) as f:\n",
    "        for line in f.readlines():\n",
    "            json_list.append(json.loads(line))\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuHV8HGqXvg_"
   },
   "source": [
    "# 모델 정의\n",
    "electra모델을 기반으로 한 classification 모델 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1662696703007,
     "user": {
      "displayName": "정용빈",
      "userId": "11947955993359770436"
     },
     "user_tz": -540
    },
    "id": "WkyrAEhAQBQV"
   },
   "outputs": [],
   "source": [
    "from transformers import ElectraTokenizerFast, ElectraModel\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, num_label):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(classifier_hidden_size, classifier_hidden_size)\n",
    "        self.dropout = nn.Dropout(classifier_dropout_prob)\n",
    "        self.output = nn.Linear(classifier_hidden_size, num_label)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = features[:, 0, :]\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class ElectraClassifier(nn.Module):\n",
    "    def __init__(self, num_label, len_tokenizer):\n",
    "        super(ElectraClassifier, self).__init__()\n",
    "\n",
    "        self.num_label = num_label\n",
    "        self.electra = ElectraModel.from_pretrained(base_model)\n",
    "        self.electra.resize_token_embeddings(len_tokenizer)\n",
    "\n",
    "        self.labels_classifier = SimpleClassifier(self.num_label)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.electra(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=None\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        logits = self.labels_classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_label),\n",
    "                                                labels.view(-1))\n",
    "            \n",
    "\n",
    "        return loss, logits    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-p0LKeGi194"
   },
   "source": [
    "# 데이터 파싱 및 tokenization 함수 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1662696707633,
     "user": {
      "displayName": "정용빈",
      "userId": "11947955993359770436"
     },
     "user_tz": -540
    },
    "id": "XO-hv7lQQGA5"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(tokenizer, form, annotations, max_len):\n",
    "    \n",
    "    polarity_data_dict = {\n",
    "        'input_ids': [],\n",
    "        'attention_mask': [],\n",
    "        'label': []\n",
    "    }\n",
    "\n",
    "    for pair in entity_property_pair:\n",
    "        isPairInOpinion = False\n",
    "        if pd.isna(form):\n",
    "            break\n",
    "        tokenized_data = tokenizer(form, pair, padding='max_length', max_length=max_len, truncation=True)\n",
    "        for annotation in annotations:\n",
    "            entity_property = annotation[0]\n",
    "            polarity = annotation[2]\n",
    "\n",
    "            if polarity == '------------':\n",
    "                continue\n",
    "\n",
    "            if entity_property == pair:\n",
    "                polarity_data_dict['input_ids'].append(tokenized_data['input_ids'])\n",
    "                polarity_data_dict['attention_mask'].append(tokenized_data['attention_mask'])\n",
    "                polarity_data_dict['label'].append(polarity_name_to_id[polarity])\n",
    "\n",
    "                isPairInOpinion = True\n",
    "                break\n",
    "\n",
    "    return polarity_data_dict\n",
    "\n",
    "\n",
    "def get_dataset(raw_data, tokenizer, max_len):\n",
    "    polarity_input_ids_list = []\n",
    "    polarity_attention_mask_list = []\n",
    "    polarity_token_labels_list = []\n",
    "\n",
    "    for utterance in raw_data:\n",
    "        polarity_data_dict = tokenize_and_align_labels(tokenizer, utterance['sentence_form'], utterance['annotation'], max_len)\n",
    "        polarity_input_ids_list.extend(polarity_data_dict['input_ids'])\n",
    "        polarity_attention_mask_list.extend(polarity_data_dict['attention_mask'])\n",
    "        polarity_token_labels_list.extend(polarity_data_dict['label'])\n",
    "\n",
    "    return TensorDataset(torch.tensor(polarity_input_ids_list), torch.tensor(polarity_attention_mask_list),\n",
    "                         torch.tensor(polarity_token_labels_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ka98lsxi--Y"
   },
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1662696779211,
     "user": {
      "displayName": "정용빈",
      "userId": "11947955993359770436"
     },
     "user_tz": -540
    },
    "id": "YL0yp7zSaX9B"
   },
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred, label_len):\n",
    "    count_list = [0]*label_len\n",
    "    hit_list = [0]*label_len\n",
    "    for i in range(len(y_true)):\n",
    "        count_list[y_true[i]] += 1\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            hit_list[y_true[i]] += 1\n",
    "    acc_list = []\n",
    "\n",
    "    for i in range(label_len):\n",
    "        acc_list.append(hit_list[i]/count_list[i])\n",
    "\n",
    "    print(\"count list: \", count_list)\n",
    "    print(\"hit_list: \", hit_list)\n",
    "    print(\"acc_list: \", acc_list)\n",
    "    print('accuracy: ', (sum(hit_list) / sum(count_list)))\n",
    "    print('macro_accuracy: ', sum(acc_list) / 3)\n",
    "    # print(y_true)\n",
    "\n",
    "    y_true = list(map(int, y_true))\n",
    "    y_pred = list(map(int, y_pred))\n",
    "\n",
    "    print('f1_score: ', f1_score(y_true, y_pred, average=None))\n",
    "    print('f1_score_micro: ', f1_score(y_true, y_pred, average='micro'))\n",
    "    print('f1_score_macro: ', f1_score(y_true, y_pred, average='macro'))\n",
    "\n",
    "def train_sentiment_analysis():\n",
    "\n",
    "    print('train_sentiment_analysis')\n",
    "    print('polarity model would be saved at ', polarity_classification_model_path)\n",
    "\n",
    "    print('loading train data')\n",
    "    train_data = jsonlload(train_data_path)\n",
    "    dev_data = jsonlload(dev_data_path)\n",
    "\n",
    "    print('tokenizing train data')\n",
    "    tokenizer = ElectraTokenizerFast.from_pretrained(base_model)\n",
    "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    print('We have added', num_added_toks, 'tokens')\n",
    "    polarity_train_data = get_dataset(train_data, tokenizer, max_len)\n",
    "    polarity_dev_data = get_dataset(dev_data, tokenizer, max_len)\n",
    "\n",
    "    polarity_train_dataloader = DataLoader(polarity_train_data, shuffle=True,\n",
    "                                                  batch_size=batch_size)\n",
    "    polarity_dev_dataloader = DataLoader(polarity_dev_data, shuffle=True,\n",
    "                                                batch_size=batch_size)\n",
    "\n",
    "    print('loading model')\n",
    "\n",
    "    polarity_model = ElectraClassifier(len(polarity_id_to_name), len(tokenizer))\n",
    "    polarity_model.to(device)\n",
    "\n",
    "\n",
    "    print('end loading')\n",
    "\n",
    "    # polarity_model_optimizer_setting\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        polarity_param_optimizer = list(polarity_model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        polarity_optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in polarity_param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in polarity_param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "    else:\n",
    "        polarity_param_optimizer = list(polarity_model.classifier.named_parameters())\n",
    "        polarity_optimizer_grouped_parameters = [{\"params\": [p for n, p in polarity_param_optimizer]}]\n",
    "\n",
    "    polarity_optimizer = AdamW(\n",
    "        polarity_optimizer_grouped_parameters,\n",
    "        lr=learning_rate,\n",
    "        eps=eps\n",
    "    )\n",
    "    epochs = num_train_epochs\n",
    "    max_grad_norm = 1.0\n",
    "    total_steps = epochs * len(polarity_train_dataloader)\n",
    "\n",
    "    polarity_scheduler = get_linear_schedule_with_warmup(\n",
    "        polarity_optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "\n",
    "    epoch_step = 0\n",
    "\n",
    "    for _ in trange(epochs, desc=\"Epoch\"):\n",
    "        polarity_model.train()\n",
    "        epoch_step += 1\n",
    "\n",
    "        # polarity train\n",
    "        polarity_total_loss = 0\n",
    "\n",
    "        for step, batch in enumerate(polarity_train_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            polarity_model.zero_grad()\n",
    "\n",
    "            loss, _ = polarity_model(b_input_ids, b_input_mask, b_labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            polarity_total_loss += loss.item()\n",
    "            # print('batch_loss: ', loss.item())\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=polarity_model.parameters(), max_norm=max_grad_norm)\n",
    "            polarity_optimizer.step()\n",
    "            polarity_scheduler.step()\n",
    "\n",
    "        avg_train_loss = polarity_total_loss / len(polarity_train_dataloader)\n",
    "        print()\n",
    "        print(\"Polarity_Epoch: \", epoch_step)\n",
    "        print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "\n",
    "        model_saved_path = polarity_classification_model_path + 'saved_model_epoch_' + str(epoch_step) + '.pt'\n",
    "        torch.save(polarity_model.state_dict(), model_saved_path)\n",
    "\n",
    "        if do_eval:\n",
    "            polarity_model.eval()\n",
    "\n",
    "            pred_list = []\n",
    "            label_list = []\n",
    "\n",
    "            for batch in polarity_dev_dataloader:\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    loss, logits = polarity_model(b_input_ids, b_input_mask, b_labels)\n",
    "\n",
    "                predictions = torch.argmax(logits, dim=-1)\n",
    "                pred_list.extend(predictions)\n",
    "                label_list.extend(b_labels)\n",
    "\n",
    "            evaluation(label_list, pred_list, len(polarity_id_to_name))\n",
    "\n",
    "    print(\"training is done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2K7iPMzFjdWO",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_sentiment_analysis()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJjry/2Jf/MZE7Ws3nDkld",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
